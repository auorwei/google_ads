#!/usr/bin/env python3
"""
æ¯å°æ—¶ç›‘æ§è„šæœ¬
è¿è¡Œå¹¿å‘ŠæŠ“å–ä»»åŠ¡
"""

import sys
import os
from datetime import datetime

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scraper import GoogleSERPScraper
from config import KEYWORDS_LIST, COUNTRY_LIST

# å¯¼å…¥æ—¥å¿—ç³»ç»Ÿ
from logger import project_logger

def main():
    """ä¸»ç›‘æ§å‡½æ•°"""
    logger = project_logger.get_hourly_logger()
    
    start_time = datetime.now()
    logger.info("ğŸ• å¼€å§‹æ¯å°æ—¶ç›‘æ§ä»»åŠ¡")
    logger.info(f"ç›‘æ§å…³é”®è¯: {KEYWORDS_LIST}")
    logger.info(f"ç›‘æ§å›½å®¶: {COUNTRY_LIST}")
    
    try:
        # åˆ›å»ºæŠ“å–å™¨
        scraper = GoogleSERPScraper()
        
        # æ‰§è¡ŒæŠ“å–
        scraper.scrape_all_combinations()
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = scraper.db.get_scrape_stats()
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        logger.info("âœ… ç›‘æ§ä»»åŠ¡å®Œæˆ")
        logger.info(f"ç”¨æ—¶: {duration}")
        logger.info(f"æ€»å¹¿å‘Šæ•°: {stats['total_ads']}")
        logger.info(f"æœ€åæŠ“å–: {stats['last_scrape']}")
        
    except Exception as e:
        logger.error(f"âŒ ç›‘æ§ä»»åŠ¡å¤±è´¥: {str(e)}")
        raise

if __name__ == "__main__":
    main()